## Concepts in Machine Learning Class 2: Supervised Learning

### Objectives

Welcome to class 2 of Concepts in Machine Learning!

By the end of this class you should be able to:

* Define and understand the limitations of supervised learning
* Differentiate between regression and classification
* Assess whether or not supervised learning is an appropriate tool for a question
* Understand basic applications of supervised learning (linear regression, logistic regression)
* Understand what bias-variance trade off and overfitting are
* Create supervised learning problem statements


### Review! What is machine learning?

### Review! Anatomy of a machine learning problem

### Review! Supervised vs unsupervised machine learning

### What is supervised machine learning?

### How do you train a machine?
* illustrate training / testing with some clear examples ("show a computer thousands of images of hand drawn numbers with the labels containing the correct integer")

### When to use supervised machine learning

### Classification

* Assign a value
* Emphasize necessity of having a 'teacher' - labeled features are what the machine uses to learn how to classify
* Decision trees, support vector machine
* example use cases
 * classic: dog vs cat

### False-positives and false-negatives

### Regression

* Predict a continuous numerical value
* point out that logistic regression is actually a classification method
* linear/polynomial regression
* example use cases
 * classic: predicting income

### Bias-variance trade off
* Bias is the amount of error introduced by approximating real-world phenomena with a simplified model.
* Variance is how much your model's test error changes based on variation in the training data. It reflects the model's sensitivity to the idiosyncrasies of the data set it was trained on.
* As a model increases in complexity and it becomes more wiggly (flexible), its bias decreases (it does a good job of explaining the training data), but variance increases (it doesn't generalize as well). Ultimately, in order to have a good model, you need one with low bias and low variance.

### How to mitigate overfitting

1. More training data
2. 

### Evaluating a supervised learning model

Loss functions

### Practice with problem statements
Use Ted Lederas cvd dataset variables to construct a problem statement. One classification and one regression.

### Review! When to use supervised machine learning

### Review! Regression vs classification

### Review! Bias-variance trade off

### Review! Evaluating a supervised machine learning model

### Next week: Unsupervised learning

### Reading materials
